{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classification on Wine Quality Dataset\n",
    "\n",
    "## Visualization\n",
    "\n",
    "## Preprocessing\n",
    "- Gaussianization\n",
    "- PCA\n",
    "(But keep both reduced and not-reduced datasets to see which one performs better)\n",
    "- Show effect of gaussianization on separability\n",
    "## Methodology\n",
    "- KFold using min DCF for selecting the\n",
    "- Priors (0.1, 0.5, 0.9)\n",
    "- Models used (MVG, LinReg, QuadLinReg, SVM(all kernels), GMM)\n",
    "-\n",
    "- Thresholds\n",
    "- Take the best 2 models and perform further calibration (plot ROC, DCF, Bayes error plot)\n",
    "- Model fusion\n",
    "\n",
    "# Integrate pandas support into grid_cv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tiblib import load_wine\n",
    "from tiblib.model_selection import grid_cv_multiprior\n",
    "from tiblib.preprocessing import Gaussianizer, StandardScaler, PCA\n",
    "from tiblib.classification import GaussianClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_preproc\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "Full\t\t& 0.797\t& 0.313\t& 0.839\t\\\\\n",
      "Naive\t\t& 0.856\t& 0.418\t& 0.881\t\\\\\n",
      "Tied\t\t& 0.818\t& 0.338\t& 0.741\t\\\\\n",
      "Naive, Tied\t\t& 0.860\t& 0.405\t& 0.944\t\\\\\n",
      "Gaussianizer\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "Full\t\t& 0.772\t& 0.299\t& 0.772\t\\\\\n",
      "Naive\t\t& 0.863\t& 0.445\t& 0.863\t\\\\\n",
      "Tied\t\t& 0.786\t& 0.351\t& 0.849\t\\\\\n",
      "Naive, Tied\t\t& 0.866\t& 0.443\t& 0.945\t\\\\\n",
      "StandardScaler\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "Full\t\t& 0.784\t& 0.310\t& 0.855\t\\\\\n",
      "Naive\t\t& 0.867\t& 0.419\t& 0.926\t\\\\\n",
      "Tied\t\t& 0.841\t& 0.335\t& 0.759\t\\\\\n",
      "Naive, Tied\t\t& 0.868\t& 0.409\t& 0.947\t\\\\\n",
      "StandardScaler_PCA (d=9)\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "Full\t\t& 0.829\t& 0.317\t& 0.810\t\\\\\n",
      "Naive\t\t& 0.815\t& 0.393\t& 0.866\t\\\\\n",
      "Tied\t\t& 0.835\t& 0.342\t& 0.746\t\\\\\n",
      "Naive, Tied\t\t& 0.823\t& 0.339\t& 0.782\t\\\\\n",
      "StandardScaler_PCA (d=5)\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "Full\t\t& 0.865\t& 0.401\t& 0.893\t\\\\\n",
      "Naive\t\t& 0.862\t& 0.434\t& 0.898\t\\\\\n",
      "Tied\t\t& 0.854\t& 0.388\t& 0.914\t\\\\\n",
      "Naive, Tied\t\t& 0.854\t& 0.387\t& 0.923\t\\\\\n",
      "Gaussianizer_StandardScaler_PCA (d=9)\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "Full\t\t& 0.818\t& 0.306\t& 0.732\t\\\\\n",
      "Naive\t\t& 0.832\t& 0.416\t& 0.799\t\\\\\n",
      "Tied\t\t& 0.816\t& 0.359\t& 0.802\t\\\\\n",
      "Naive, Tied\t\t& 0.813\t& 0.356\t& 0.816\t\\\\\n",
      "Gaussianizer_StandardScaler_PCA (d=5)\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "Full\t\t& 0.838\t& 0.392\t& 0.877\t\\\\\n",
      "Naive\t\t& 0.874\t& 0.431\t& 0.924\t\\\\\n",
      "Tied\t\t& 0.829\t& 0.391\t& 0.980\t\\\\\n",
      "Naive, Tied\t\t& 0.822\t& 0.392\t& 0.987\t\\\\\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_wine()\n",
    "\n",
    "model = GaussianClassifier\n",
    "hyperparams = {'tied':[False, True],\n",
    "               'naive':[False, True]}\n",
    "\n",
    "gaussianizer = Gaussianizer()\n",
    "scaler = StandardScaler()\n",
    "pca1 = PCA(n_dims=9)\n",
    "pca2 = PCA(n_dims=5)\n",
    "preprocessings = [\n",
    "    [],\n",
    "    [gaussianizer],\n",
    "    [scaler],\n",
    "    [scaler, pca1],\n",
    "    [scaler, pca2],\n",
    "    [gaussianizer, scaler, pca1],\n",
    "    [gaussianizer, scaler, pca2],\n",
    "]\n",
    "prefix = 'gc'\n",
    "pis = [0.1, 0.5, 0.9]\n",
    "for pr in preprocessings:\n",
    "    if len(pr) > 0:\n",
    "        filename = '_'.join([str(p) for p in pr])\n",
    "    else:\n",
    "        filename = 'no_preproc'\n",
    "    print(filename) # Prints current preprocessings in string form\n",
    "    grid_cv_multiprior(X_train, y_train, pis=pis,\n",
    "            preprocessing=pr,\n",
    "            classifier=model, hyperparams=hyperparams, filename=f'results/results_{prefix}_{filename}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_preproc\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "LogReg ($\\lambda = 0.1$)\t\t& 0.874\t& 0.423\t& 0.974\t\\\\\n",
      "LogReg ($\\lambda = 0.01$)\t\t& 0.844\t& 0.400\t& 0.816\t\\\\\n",
      "LogReg ($\\lambda = 0.001$)\t\t& 0.826\t& 0.354\t& 0.684\t\\\\\n",
      "LogReg ($\\lambda = 0.0001$)\t\t& 0.856\t& 0.360\t& 0.643\t\\\\\n",
      "StandardScaler\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "LogReg ($\\lambda = 0.1$)\t\t& 0.851\t& 0.355\t& 0.808\t\\\\\n",
      "LogReg ($\\lambda = 0.01$)\t\t& 0.845\t& 0.351\t& 0.666\t\\\\\n",
      "LogReg ($\\lambda = 0.001$)\t\t& 0.847\t& 0.358\t& 0.693\t\\\\\n",
      "LogReg ($\\lambda = 0.0001$)\t\t& 0.852\t& 0.356\t& 0.666\t\\\\\n",
      "StandardScaler_PCA (d=9)\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "LogReg ($\\lambda = 0.1$)\t\t& 0.842\t& 0.356\t& 0.779\t\\\\\n",
      "LogReg ($\\lambda = 0.01$)\t\t& 0.845\t& 0.347\t& 0.660\t\\\\\n",
      "LogReg ($\\lambda = 0.001$)\t\t& 0.854\t& 0.361\t& 0.670\t\\\\\n",
      "LogReg ($\\lambda = 0.0001$)\t\t& 0.840\t& 0.352\t& 0.661\t\\\\\n",
      "StandardScaler_PCA (d=5)\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "LogReg ($\\lambda = 0.1$)\t\t& 0.844\t& 0.387\t& 0.881\t\\\\\n",
      "LogReg ($\\lambda = 0.01$)\t\t& 0.856\t& 0.383\t& 0.847\t\\\\\n",
      "LogReg ($\\lambda = 0.001$)\t\t& 0.847\t& 0.381\t& 0.843\t\\\\\n",
      "LogReg ($\\lambda = 0.0001$)\t\t& 0.844\t& 0.388\t& 0.848\t\\\\\n"
     ]
    }
   ],
   "source": [
    "from tiblib.classification import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_wine()\n",
    "\n",
    "model = LogisticRegression\n",
    "hyperparams = {'l':[1e-1, 1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "gaussianizer = Gaussianizer()\n",
    "scaler = StandardScaler()\n",
    "pca1 = PCA(n_dims=9)\n",
    "pca2 = PCA(n_dims=5)\n",
    "preprocessings = [\n",
    "    [],\n",
    "    [scaler],\n",
    "    [scaler, pca1],\n",
    "    [scaler, pca2]\n",
    "]\n",
    "prefix = 'lr'\n",
    "pis = [0.1, 0.5, 0.9]\n",
    "for pr in preprocessings:\n",
    "    if len(pr) > 0:\n",
    "        filename = '_'.join([str(p) for p in pr])\n",
    "    else:\n",
    "        filename = 'no_preproc'\n",
    "    print(filename) # Prints current preprocessings in string form\n",
    "    grid_cv_multiprior(X_train, y_train, pis=pis,\n",
    "            preprocessing=pr,\n",
    "            classifier=model, hyperparams=hyperparams, filename=f'results/results_{prefix}_{filename}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quadratic Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_preproc\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "QuadLogReg ($\\lambda = 0.1$)\t\t& 0.856\t& 0.389\t& 0.794\t\\\\\n",
      "QuadLogReg ($\\lambda = 0.01$)\t\t& 0.857\t& 0.366\t& 0.885\t\\\\\n",
      "QuadLogReg ($\\lambda = 0.001$)\t\t& 0.859\t& 0.393\t& 0.871\t\\\\\n",
      "QuadLogReg ($\\lambda = 0.0001$)\t\t& 0.827\t& 0.366\t& 0.861\t\\\\\n",
      "StandardScaler\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "QuadLogReg ($\\lambda = 0.1$)\t\t& 0.825\t& 0.325\t& 0.840\t\\\\\n"
     ]
    }
   ],
   "source": [
    "from tiblib.classification import QuadraticLogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_wine()\n",
    "\n",
    "model = QuadraticLogisticRegression\n",
    "hyperparams = {'l':[1e-1, 1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "gaussianizer = Gaussianizer()\n",
    "scaler = StandardScaler()\n",
    "pca1 = PCA(n_dims=9)\n",
    "pca2 = PCA(n_dims=5)\n",
    "preprocessings = [\n",
    "    [],\n",
    "    [scaler],\n",
    "    [scaler, pca1],\n",
    "    [scaler, pca2]\n",
    "]\n",
    "prefix = 'lr'\n",
    "pis = [0.1, 0.5, 0.9]\n",
    "for pr in preprocessings:\n",
    "    if len(pr) > 0:\n",
    "        filename = '_'.join([str(p) for p in pr])\n",
    "    else:\n",
    "        filename = 'no_preproc'\n",
    "    print(filename) # Prints current preprocessings in string form\n",
    "    grid_cv_multiprior(X_train, y_train, pis=pis,\n",
    "            preprocessing=pr,\n",
    "            classifier=model, hyperparams=hyperparams, filename=f'results/results_{prefix}_{filename}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GMM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_preproc\n",
      "Showing results for pi = [0.1, 0.5, 0.9]\n",
      "GMM (4 components, $\\alpha = 0.1$)\t\t& 0.830\t& 0.326\t& 0.801\t\\\\\n",
      "GMM (4 components, $\\alpha = 0.5$)\t\t& 0.814\t& 0.347\t& 0.759\t\\\\\n",
      "GMM (4 components, $\\alpha = 1$)\t\t& 0.760\t& 0.323\t& 0.643\t\\\\\n",
      "GMM (8 components, $\\alpha = 0.1$)\t\t& 0.793\t& 0.335\t& 0.763\t\\\\\n",
      "GMM (8 components, $\\alpha = 0.5$)\t\t& 0.811\t& 0.347\t& 0.734\t\\\\\n",
      "GMM (8 components, $\\alpha = 1$)\t\t& 0.710\t& 0.331\t& 0.679\t\\\\\n",
      "GMM (16 components, $\\alpha = 0.1$)\t\t& 0.813\t& 0.357\t& 0.879\t\\\\\n",
      "GMM (16 components, $\\alpha = 0.5$)\t\t& 0.777\t& 0.350\t& 0.823\t\\\\\n",
      "GMM (16 components, $\\alpha = 1$)\t\t& 0.777\t& 0.306\t& 0.748\t\\\\\n",
      "GMM (Diag, 4 components, $\\alpha = 0.1$)\t\t& 0.860\t& 0.421\t& 0.842\t\\\\\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 27\u001B[0m\n\u001B[0;32m     25\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mno_preproc\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(filename) \u001B[38;5;66;03m# Prints current preprocessings in string form\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m \u001B[43mgrid_cv_multiprior\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyperparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresults/results_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mprefix\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mfilename\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\model_selection\\cv.py:130\u001B[0m, in \u001B[0;36mgrid_cv_multiprior\u001B[1;34m(X, y, pis, preprocessing, classifier, hyperparams, filename)\u001B[0m\n\u001B[0;32m    128\u001B[0m model \u001B[38;5;241m=\u001B[39m Pipeline(transformers\u001B[38;5;241m=\u001B[39mpreprocessing, classifier\u001B[38;5;241m=\u001B[39mc)\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pi \u001B[38;5;129;01min\u001B[39;00m pis:\n\u001B[1;32m--> 130\u001B[0m     best_score, best_act_score \u001B[38;5;241m=\u001B[39m \u001B[43mCVMinDCF\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    131\u001B[0m     pi_min_dcf\u001B[38;5;241m.\u001B[39mappend(best_score)\n\u001B[0;32m    132\u001B[0m     results\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrior\u001B[39m\u001B[38;5;124m'\u001B[39m : pi,\n\u001B[0;32m    133\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m'\u001B[39m : \u001B[38;5;28mstr\u001B[39m(c),\n\u001B[0;32m    134\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMin DCF\u001B[39m\u001B[38;5;124m'\u001B[39m : best_score,\n\u001B[0;32m    135\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAct DCF\u001B[39m\u001B[38;5;124m'\u001B[39m : best_act_score,\n\u001B[0;32m    136\u001B[0m                     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams})\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\model_selection\\cv.py:53\u001B[0m, in \u001B[0;36mCVMinDCF\u001B[1;34m(model, X, y, K, pi, calibration, _lambda)\u001B[0m\n\u001B[0;32m     50\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m X[train_indices], y[train_indices]\n\u001B[0;32m     51\u001B[0m X_val, y_val \u001B[38;5;241m=\u001B[39m X[val_indices], y[val_indices]\n\u001B[1;32m---> 53\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m val_scores \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_scores(X_val, get_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m calibration:\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\classification\\pipeline.py:25\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformers:\n\u001B[0;32m     24\u001B[0m     X_transf \u001B[38;5;241m=\u001B[39m t\u001B[38;5;241m.\u001B[39mfit_transform(X_transf)\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_transf\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\classification\\gaussian_mixture.py:159\u001B[0m, in \u001B[0;36mGaussianMixtureClassifier.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    155\u001B[0m X_c \u001B[38;5;241m=\u001B[39m X[y \u001B[38;5;241m==\u001B[39m c]\n\u001B[0;32m    156\u001B[0m gmm \u001B[38;5;241m=\u001B[39m GaussianMixtureModel(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_components, algorithm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgorithm,\n\u001B[0;32m    157\u001B[0m                            alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha, psi\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpsi, tied\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtied, diag\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiag,\n\u001B[0;32m    158\u001B[0m                            stop_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_delta)\n\u001B[1;32m--> 159\u001B[0m \u001B[43mgmm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_c\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels[c] \u001B[38;5;241m=\u001B[39m gmm\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\classification\\gaussian_mixture.py:56\u001B[0m, in \u001B[0;36mGaussianMixtureModel.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_em(X)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlbg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 56\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_lbg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\classification\\gaussian_mixture.py:116\u001B[0m, in \u001B[0;36mGaussianMixtureModel._fit_lbg\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurr_components \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurr_components, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSomething went wrong when doubling components\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 116\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_em\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\classification\\gaussian_mixture.py:89\u001B[0m, in \u001B[0;36mGaussianMixtureModel._fit_em\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     86\u001B[0m s[s \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpsi] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpsi\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcovariances \u001B[38;5;241m=\u001B[39m U \u001B[38;5;241m@\u001B[39m (s[:,:,np\u001B[38;5;241m.\u001B[39mnewaxis] \u001B[38;5;241m*\u001B[39m U\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha\n\u001B[1;32m---> 89\u001B[0m loglikelihood, responsibilities \u001B[38;5;241m=\u001B[39m \u001B[43mlogpdf_GMM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmeans\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcovariances\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m sum_ll \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(loglikelihood)\n\u001B[0;32m     91\u001B[0m delta_ll \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mabs(sum_ll \u001B[38;5;241m-\u001B[39m last_ll)\n",
      "File \u001B[1;32m~\\Documents\\Python Scripts\\polito-mlpr\\tiblib\\utils.py:146\u001B[0m, in \u001B[0;36mlogpdf_GMM\u001B[1;34m(X, gmm)\u001B[0m\n\u001B[0;32m    144\u001B[0m loglikelihood \u001B[38;5;241m=\u001B[39m scipy\u001B[38;5;241m.\u001B[39mspecial\u001B[38;5;241m.\u001B[39mlogsumexp(logscores, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    145\u001B[0m \u001B[38;5;66;03m# responsibilities = np.exp(logscores) / np.sum(np.exp(logscores), axis=0)\u001B[39;00m\n\u001B[1;32m--> 146\u001B[0m responsibilities \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogscores\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mloglikelihood\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loglikelihood, responsibilities\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tiblib.classification import GaussianMixtureClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_wine()\n",
    "\n",
    "model = GaussianMixtureClassifier\n",
    "hyperparams = {'tied':[False, True],\n",
    "               'diag':[False, True],\n",
    "               'n_components':[4,8,16],\n",
    "               'alpha':[0.1, 0.5, 1]}\n",
    "prefix = 'gmm'\n",
    "pis = [0.1, 0.5, 0.9]\n",
    "gaussianizer = Gaussianizer()\n",
    "scaler = StandardScaler()\n",
    "pca1 = PCA(n_dims=9)\n",
    "pca2 = PCA(n_dims=5)\n",
    "preprocessings = [\n",
    "    [],\n",
    "    [gaussianizer],\n",
    "    [scaler],\n",
    "]\n",
    "for pr in preprocessings:\n",
    "    if len(pr) > 0:\n",
    "        filename = '_'.join([str(p) for p in pr])\n",
    "    else:\n",
    "        filename = 'no_preproc'\n",
    "    print(filename) # Prints current preprocessings in string form\n",
    "    grid_cv_multiprior(X_train, y_train, pis=pis,\n",
    "            preprocessing=pr,\n",
    "            classifier=model, hyperparams=hyperparams, filename=f'results/results_{prefix}_{filename}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tiblib.classification import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_wine()\n",
    "\n",
    "model = SVC\n",
    "hyperparams = {'C':[1e-1, 1e-2, 1e-3, 1e-4],\n",
    "               'kernel': ['linear', 'poly', 'radial']}\n",
    "prefix = 'svm'\n",
    "pis = [0.1, 0.5, 0.9]\n",
    "gaussianizer = Gaussianizer()\n",
    "scaler = StandardScaler()\n",
    "pca1 = PCA(n_dims=9)\n",
    "pca2 = PCA(n_dims=5)\n",
    "preprocessings = [\n",
    "    [],\n",
    "    [gaussianizer],\n",
    "    [scaler],\n",
    "    [scaler, pca1],\n",
    "    [scaler, pca2]\n",
    "]\n",
    "for pr in preprocessings:\n",
    "    if len(pr) > 0:\n",
    "        filename = '_'.join([str(p) for p in pr])\n",
    "    else:\n",
    "        filename = 'no_preproc'\n",
    "    print(filename) # Prints current preprocessings in string form\n",
    "    grid_cv_multiprior(X_train, y_train, pis=pis,\n",
    "            preprocessing=pr,\n",
    "            classifier=model, hyperparams=hyperparams, filename=f'results/results_{prefix}_{filename}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-d2c9f13c",
   "language": "python",
   "display_name": "PyCharm (eurecom-malis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}